{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/avilashahaldar/apriori-analysis-of-grocery-baskets?scriptVersionId=191206757\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"79c30899","metadata":{"papermill":{"duration":0.006718,"end_time":"2024-08-04T23:23:12.285194","exception":false,"start_time":"2024-08-04T23:23:12.278476","status":"completed"},"tags":[]},"source":["Hi! Today, we're going to be looking at apriori analysis of people's grocery baskets to find which items people are most likely to buy together. Information on the dataset can be found [here](https://www.kaggle.com/datasets/heeraldedhia/groceries-dataset/data). Let's get started!"]},{"cell_type":"code","execution_count":1,"id":"b1513c41","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-04T23:23:12.299887Z","iopub.status.busy":"2024-08-04T23:23:12.299483Z","iopub.status.idle":"2024-08-04T23:23:14.93155Z","shell.execute_reply":"2024-08-04T23:23:14.930163Z"},"papermill":{"duration":2.642946,"end_time":"2024-08-04T23:23:14.934756","exception":false,"start_time":"2024-08-04T23:23:12.29181","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/apriori2-img/Apriori2.png\n","/kaggle/input/groceries-dataset/Groceries_dataset.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from sklearn.preprocessing import LabelEncoder\n","from itertools import combinations, chain\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"055c1676","metadata":{"papermill":{"duration":0.006113,"end_time":"2024-08-04T23:23:14.947425","exception":false,"start_time":"2024-08-04T23:23:14.941312","status":"completed"},"tags":[]},"source":["# Exploring and Processing the Data"]},{"cell_type":"code","execution_count":2,"id":"28254290","metadata":{"execution":{"iopub.execute_input":"2024-08-04T23:23:14.962204Z","iopub.status.busy":"2024-08-04T23:23:14.961567Z","iopub.status.idle":"2024-08-04T23:23:15.041274Z","shell.execute_reply":"2024-08-04T23:23:15.039971Z"},"papermill":{"duration":0.090301,"end_time":"2024-08-04T23:23:15.0441","exception":false,"start_time":"2024-08-04T23:23:14.953799","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Member_number</th>\n","      <th>Date</th>\n","      <th>itemDescription</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1808</td>\n","      <td>21-07-2015</td>\n","      <td>tropical fruit</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2552</td>\n","      <td>05-01-2015</td>\n","      <td>whole milk</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2300</td>\n","      <td>19-09-2015</td>\n","      <td>pip fruit</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1187</td>\n","      <td>12-12-2015</td>\n","      <td>other vegetables</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3037</td>\n","      <td>01-02-2015</td>\n","      <td>whole milk</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Member_number        Date   itemDescription\n","0           1808  21-07-2015    tropical fruit\n","1           2552  05-01-2015        whole milk\n","2           2300  19-09-2015         pip fruit\n","3           1187  12-12-2015  other vegetables\n","4           3037  01-02-2015        whole milk"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["groceries_data = pd.read_csv(\"/kaggle/input/groceries-dataset/Groceries_dataset.csv\")\n","groceries_data.head()"]},{"cell_type":"markdown","id":"e2dfb1a1","metadata":{"papermill":{"duration":0.006572,"end_time":"2024-08-04T23:23:15.05787","exception":false,"start_time":"2024-08-04T23:23:15.051298","status":"completed"},"tags":[]},"source":["Some of the checks I did before using this data were checking for NaNs (of which there were none), checking all the dates were valid (yes, they were), and checking the unique itemDescription values to ensure none of them were misspelled or duplicated with both American and British spellings. The date range is over the course of 2 years, from Jan. 1, 2014, to Dec. 30, 2015. I believe Dec. 31, 2015 was a bank holiday or weekend.\n","\n","We're going to convert all the item descriptions to integers just so they take up less space in memory. Strings are expensive! And because there are 167 unique categories, we're going to use the int8 dtype instead of the default int64, since int64 is overkill. This is incredibly important the larger the dataset gets, since using unnecessarily large dtypes can cause memory costs to spiral in the worst-case scenarios.\n","\n","At the same time, it's important to make sure our datatype won't break things if we have a pipeline where data gets added in the future. If we expected lots of categories to be added in the future (enough to take us over 256), we might set to int16 instead of int8, since int8 will break once we reach 256 categories. However, since our data here is static, we can use int8.\n","\n","We're also going to change the dtype of the Member Number. Currently, Member Number goes from 1000 to 5000 inclusive and is int64 dtype. We can set it to int16."]},{"cell_type":"code","execution_count":3,"id":"fca2cf45","metadata":{"execution":{"iopub.execute_input":"2024-08-04T23:23:15.073913Z","iopub.status.busy":"2024-08-04T23:23:15.073483Z","iopub.status.idle":"2024-08-04T23:23:15.120723Z","shell.execute_reply":"2024-08-04T23:23:15.119334Z"},"papermill":{"duration":0.058683,"end_time":"2024-08-04T23:23:15.123854","exception":false,"start_time":"2024-08-04T23:23:15.065171","status":"completed"},"tags":[]},"outputs":[],"source":["itemEncoder = LabelEncoder()\n","itemEncoder.fit(groceries_data[\"itemDescription\"])\n","\n","groceries_data[\"itemDescription\"] = (itemEncoder.transform(groceries_data[\"itemDescription\"]) - 100).astype('int8')\n","groceries_data[\"Date\"] = pd.to_datetime(groceries_data[\"Date\"], format=\"%d-%m-%Y\")\n","groceries_data[\"Member_number\"] = groceries_data[\"Member_number\"].astype('int16')\n","\n","# We'll need this later to convert back\n","itemEncoderDict = dict(zip(itemEncoder.transform(itemEncoder.classes_) - 100, itemEncoder.classes_))"]},{"cell_type":"markdown","id":"d0d8a653","metadata":{"papermill":{"duration":0.006777,"end_time":"2024-08-04T23:23:15.137611","exception":false,"start_time":"2024-08-04T23:23:15.130834","status":"completed"},"tags":[]},"source":["Let's now take a look at the transformed data and also its shape. We can see that we have a decent number of rows for a proof of concept - a bit less than 40k rows of data. I doubt a megabusiness (e.g. Walmart) would base a business strategy on this amount of data, but it's definitely god for a smaller business, and definitely works for a proof of concept."]},{"cell_type":"code","execution_count":4,"id":"e83b7be9","metadata":{"execution":{"iopub.execute_input":"2024-08-04T23:23:15.152906Z","iopub.status.busy":"2024-08-04T23:23:15.152482Z","iopub.status.idle":"2024-08-04T23:23:15.160467Z","shell.execute_reply":"2024-08-04T23:23:15.159038Z"},"papermill":{"duration":0.01847,"end_time":"2024-08-04T23:23:15.162805","exception":false,"start_time":"2024-08-04T23:23:15.144335","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(38765, 3)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["groceries_data.shape"]},{"cell_type":"code","execution_count":5,"id":"76000f14","metadata":{"execution":{"iopub.execute_input":"2024-08-04T23:23:15.178996Z","iopub.status.busy":"2024-08-04T23:23:15.178508Z","iopub.status.idle":"2024-08-04T23:23:15.190287Z","shell.execute_reply":"2024-08-04T23:23:15.18912Z"},"papermill":{"duration":0.022952,"end_time":"2024-08-04T23:23:15.193025","exception":false,"start_time":"2024-08-04T23:23:15.170073","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Member_number</th>\n","      <th>Date</th>\n","      <th>itemDescription</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1808</td>\n","      <td>2015-07-21</td>\n","      <td>56</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2552</td>\n","      <td>2015-01-05</td>\n","      <td>64</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2300</td>\n","      <td>2015-09-19</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1187</td>\n","      <td>2015-12-12</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3037</td>\n","      <td>2015-02-01</td>\n","      <td>64</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Member_number       Date  itemDescription\n","0           1808 2015-07-21               56\n","1           2552 2015-01-05               64\n","2           2300 2015-09-19                9\n","3           1187 2015-12-12                2\n","4           3037 2015-02-01               64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["groceries_data.head()"]},{"cell_type":"markdown","id":"b00f48c4","metadata":{"papermill":{"duration":0.007292,"end_time":"2024-08-04T23:23:15.207885","exception":false,"start_time":"2024-08-04T23:23:15.200593","status":"completed"},"tags":[]},"source":["Let's check if any people buy multiple things on the same day. For that, we can group by member_number and date and see if any of the counts are > 1."]},{"cell_type":"code","execution_count":6,"id":"e8a19b2f","metadata":{"execution":{"iopub.execute_input":"2024-08-04T23:23:15.225327Z","iopub.status.busy":"2024-08-04T23:23:15.224889Z","iopub.status.idle":"2024-08-04T23:23:15.252668Z","shell.execute_reply":"2024-08-04T23:23:15.251473Z"},"papermill":{"duration":0.040382,"end_time":"2024-08-04T23:23:15.255886","exception":false,"start_time":"2024-08-04T23:23:15.215504","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>itemDescription</th>\n","    </tr>\n","    <tr>\n","      <th>Member_number</th>\n","      <th>Date</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">1000</th>\n","      <th>2014-06-24</th>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2015-03-15</th>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2015-05-27</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2015-07-24</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2015-11-25</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">4999</th>\n","      <th>2015-05-16</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2015-12-26</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">5000</th>\n","      <th>2014-03-09</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2014-11-16</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2015-02-10</th>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>14963 rows × 1 columns</p>\n","</div>"],"text/plain":["                          itemDescription\n","Member_number Date                       \n","1000          2014-06-24                3\n","              2015-03-15                4\n","              2015-05-27                2\n","              2015-07-24                2\n","              2015-11-25                2\n","...                                   ...\n","4999          2015-05-16                2\n","              2015-12-26                2\n","5000          2014-03-09                2\n","              2014-11-16                2\n","              2015-02-10                3\n","\n","[14963 rows x 1 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["groceries_data.groupby([\"Member_number\", \"Date\"]).count()"]},{"cell_type":"markdown","id":"25fbd40b","metadata":{"papermill":{"duration":0.007013,"end_time":"2024-08-04T23:23:15.270399","exception":false,"start_time":"2024-08-04T23:23:15.263386","status":"completed"},"tags":[]},"source":["Yeah, that's expected, that we see lots of people buying more than 1 item on a given date. If that weren't the case, and everyone only bought 1 item a day, I'd think something's wrong with the data and it only records the first item on each person's receipt. It's good to see that's not the case. There is some other data I wish were included, e.g. whether all of this data is from the same store, what country that store is in (this could allow us to look more into regional holidays like 4th of July or Thanksgiving) and what time of day the purchases were made. There could be some interesting insights we could've pulled out from there, e.g. whether lots of people come in around lunchtime to grab a sandwich, or whether we see more folks coming in the evening for a more hefty grocery shop, or what kinds of items see a surge in buyers around certain holidays.\n","\n","Anyway, I think that does it for data processing and EDA. Let's now talk more about the analysis we're going to do.\n","\n","# Apriori Algorithm\n","\n","The **apriori algorithm** is an **unsupervised machine learning algorithm**, meaning there are no right answers or labels. Regression is a **supervised** learning algorithm, meaning it is trained using a set of correct answers, while algorithms designed to play e.g. board or video games use **reinforcement learning**, which seeks to maximize a reward like points or wins. Unsupervised learning algorithms tend to be used for clustering and association tasks. K-means clustering is a common example.\n","\n","Apriori is a type of **association rule learning**, meaning it identifies frequent patterns and associations. We'll be using apriori to find out which grocery items are often bought together. This knowledge can then be used for designing store layouts. If you want to make things easier for your consumers, you'll put frequently connected items in the same or adjacent aisles. If you want to force your buyer to walk more of the store to get what they need, you'll put these things in different aisles.\n","\n","There are already libraries in Python that can do apriori for you, but to enhance our own understanding, we're going to compute it from scratch. To do that, let's format our data a bit. Since, at this point, we don't really care who the specific members are or the exact date (only which transactions were made by the same member on the same date), we're going to create a new index where each unique value represent a unique member_number and date combination, just so we can rid ourselves of the cumbersome MultiIndex. We'll also format each unique transaction value in a list so that our functions later on can work with any length of unique transaction, assuming the lengths are the same for all rows."]},{"cell_type":"code","execution_count":7,"id":"f1e88560","metadata":{"execution":{"iopub.execute_input":"2024-08-04T23:23:15.288047Z","iopub.status.busy":"2024-08-04T23:23:15.287583Z","iopub.status.idle":"2024-08-04T23:23:15.505822Z","shell.execute_reply":"2024-08-04T23:23:15.504437Z"},"papermill":{"duration":0.230791,"end_time":"2024-08-04T23:23:15.508581","exception":false,"start_time":"2024-08-04T23:23:15.27779","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>uniqueTransaction</th>\n","    </tr>\n","    <tr>\n","      <th>Index</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1808_2015-07-21</th>\n","      <td>[56]</td>\n","    </tr>\n","    <tr>\n","      <th>2552_2015-01-05</th>\n","      <td>[64]</td>\n","    </tr>\n","    <tr>\n","      <th>2300_2015-09-19</th>\n","      <td>[9]</td>\n","    </tr>\n","    <tr>\n","      <th>1187_2015-12-12</th>\n","      <td>[2]</td>\n","    </tr>\n","    <tr>\n","      <th>3037_2015-02-01</th>\n","      <td>[64]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4471_2014-10-08</th>\n","      <td>[35]</td>\n","    </tr>\n","    <tr>\n","      <th>2022_2014-02-23</th>\n","      <td>[-81]</td>\n","    </tr>\n","    <tr>\n","      <th>1097_2014-04-16</th>\n","      <td>[-83]</td>\n","    </tr>\n","    <tr>\n","      <th>1510_2014-12-03</th>\n","      <td>[-36]</td>\n","    </tr>\n","    <tr>\n","      <th>1521_2014-12-26</th>\n","      <td>[-76]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>38006 rows × 1 columns</p>\n","</div>"],"text/plain":["                uniqueTransaction\n","Index                            \n","1808_2015-07-21              [56]\n","2552_2015-01-05              [64]\n","2300_2015-09-19               [9]\n","1187_2015-12-12               [2]\n","3037_2015-02-01              [64]\n","...                           ...\n","4471_2014-10-08              [35]\n","2022_2014-02-23             [-81]\n","1097_2014-04-16             [-83]\n","1510_2014-12-03             [-36]\n","1521_2014-12-26             [-76]\n","\n","[38006 rows x 1 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# We don't care if someone buys multiple of the same item on the same day, so we just remove duplicated rows.\n","groceries_apriori = groceries_data.copy().drop_duplicates()\n","\n","# Member_number and Date will be our useful index columns, since we want to group transactions by person and date.\n","groceries_apriori = groceries_apriori.set_index([\"Member_number\", \"Date\"])\n","\n","groceries_apriori.index = groceries_apriori.index.get_level_values(\"Member_number\").astype(str) + \"_\" + groceries_apriori.index.get_level_values(\"Date\").astype(str)\n","groceries_apriori.index.names = [\"Index\"]\n","groceries_apriori[\"itemDescription\"] = groceries_apriori[\"itemDescription\"].apply(lambda x: [x])\n","groceries_apriori = groceries_apriori.rename(columns={\"itemDescription\": \"uniqueTransaction\"})\n","\n","# We have this new format where the items are in lists so we can reuse the same functions for different lengths.\n","# E.g. When we get to considering combinations of 2, each row will have a list of 2 items bought on a given date by a given member.\n","groceries_apriori"]},{"cell_type":"markdown","id":"81b401da","metadata":{"papermill":{"duration":0.007826,"end_time":"2024-08-04T23:23:15.52513","exception":false,"start_time":"2024-08-04T23:23:15.517304","status":"completed"},"tags":[]},"source":["To implement apriori, we start with **frequent itemset mining**, which is just a fancy way of saying, narrowing our dataset down to items which are bought above a certain frequency threshold. Since we're looking for general trends, we don't want to be focusing on items which have maybe only been bought a few times in the entire two-year period. This is arbitrary, but I'm going to set our threshold at 48 (i.e. items have been bought twice a month in the 2-year period our data covers). Since we didn't have so much data to begin with that our program would be very slow to run, I think this is fine. If we had millions of rows, I'd be a lot more aggressive with this pruning.\n","\n","If we had data on revenues and costs by item category, it would be interesting to look at the product categories that got removed and see if they are even profitable to sell to begin with.\n","\n","We are also going to see which combinations of Member_number and Date only yield 1 item, meaning the person only bought a single item on that date. These rows are not useful for determining item associations, so we'll be removing them.\n","\n","From there, we get all combinations of 2 items sharing a member and date index and keep the combinations that occur more than the common_combo_threshold. We then move up to considering 3 items and keep all transactions where 2 of the 3 items form a common combination of 2. This is best explained with the below diagram:\n","\n","<img src='https://storage.googleapis.com/kagglesdsdata/datasets/5495722/9105794/Apriori2.png?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20240804%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240804T230423Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=49232ba444d241a053430c2218018a6eea2b0ab944ce2b887a37b212e121bb0c3721ffde98fe30095d13e79d5c71260e4648900576820338066443007a6abce0f6b07c4a48d879797c99e0f5bf4579034a4b121e593e4a8b6398d5bd743de22bb1ebeb5a8793332c30b5fc678c6c81c681c25cbc9e877c48a7d86ce5eab1754ebccf7c1bb88035541af824e6e2ee5df33238ce7cf24623b46268ffd7f3c54be5356abf62069c59f4ce0e241619fecddcc1a1a8ce7e286e2370ab1184fae36bca75716213b25428d3421a3d2ed6960ac811ff3774e1fb3ce5bd37104ce82a5a644bc0ac95356934bb4c2976b5158eb26ba3462d3aac471698d3a645a24944b10e' width=600>\n","\n","If something item or combination of items doesn't meet our minimum threshold, and and all its children are excluded."]},{"cell_type":"code","execution_count":8,"id":"d4204bd8","metadata":{"execution":{"iopub.execute_input":"2024-08-04T23:23:15.542925Z","iopub.status.busy":"2024-08-04T23:23:15.542442Z","iopub.status.idle":"2024-08-04T23:23:20.185669Z","shell.execute_reply":"2024-08-04T23:23:20.184569Z"},"papermill":{"duration":4.655745,"end_time":"2024-08-04T23:23:20.188591","exception":false,"start_time":"2024-08-04T23:23:15.532846","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Getting list of all items and combinations of length 2 for each unique index\n","                         allItems  \\\n","Index                               \n","1000_2014-06-24       [5, 28, 64]   \n","1000_2015-03-15  [30, 32, 64, 65]   \n","1000_2015-05-27           [8, 38]   \n","1000_2015-07-24         [-80, -8]   \n","1000_2015-11-25         [-27, 30]   \n","\n","                                                            combos  \n","Index                                                               \n","1000_2014-06-24                       [[5, 28], [5, 64], [28, 64]]  \n","1000_2015-03-15  [[30, 32], [30, 64], [30, 65], [32, 64], [32, ...  \n","1000_2015-05-27                                          [[8, 38]]  \n","1000_2015-07-24                                        [[-80, -8]]  \n","1000_2015-11-25                                        [[-27, 30]]  \n","\n","Getting the common combinations of length 2\n","[2, 64]      222\n","[22, 64]     209\n","[38, 64]     174\n","[64, 65]     167\n","[2, 22]      158\n","[2, 38]      145\n","[30, 64]     134\n","[56, 64]     123\n","[2, 65]      121\n","[22, 38]     121\n","[22, 65]     117\n","[23, 64]     113\n","[-89, 64]    107\n","[-88, 64]    107\n","[-70, 64]    107\n","[9, 64]       99\n","[5, 64]       97\n","[33, 64]      95\n","[2, 56]       94\n","[22, 56]      91\n","[2, 30]       90\n","[-80, 64]     90\n","[30, 38]      89\n","[38, 65]      87\n","[22, 23]      86\n","[30, 65]      86\n","[-5, 64]      84\n","[-88, 2]      82\n","[38, 56]      81\n","[22, 30]      80\n","[-51, 64]     79\n","[-44, 64]     79\n","[23, 38]      79\n","[2, 23]       79\n","[56, 65]      78\n","[-44, 2]      77\n","[11, 64]      75\n","[2, 33]       74\n","[2, 9]        74\n","[9, 22]       74\n","[-70, 2]      72\n","[-88, 38]     72\n","[22, 33]      71\n","[-89, 2]      70\n","[-88, 22]     70\n","[-92, 64]     70\n","[-85, 64]     70\n","[-70, 22]     70\n","Name: count, dtype: int64\n"]}],"source":["def select_items_bought_with_high_frequency(groceries_data: pd.DataFrame, value_col: str, item_frequency_threshold: int = 48) -> pd.DataFrame:\n","    \"\"\"\n","    Frequency itemset mining: Only keeping rows corresponding to items that are bought more than item_frequency_threshold times.\n","    Each row in groceries_data corresponds to a unique transaction.\n","    We return the groceries_data dataframe with rows removed corresponding to infrequently bought items.\n","    \"\"\"\n","    if groceries_data.empty:\n","        return groceries_data\n","    items_bought_frequently = groceries_data[value_col].value_counts() >= item_frequency_threshold\n","    groceries_data = groceries_data[groceries_data[value_col].isin(items_bought_frequently[items_bought_frequently].index)]\n","    return groceries_data\n","\n","def get_rows_with_num_transactions(groceries_data: pd.DataFrame, value_col: str) -> pd.DataFrame:\n","    \"\"\"\n","    Assuming that each uniqueTransaction in groceries_data has length num_items_per_transaction, and we want to keep indices\n","    where more than num_items_per_transaction have been bought, we just need to keep the indices that appear more than once.\n","    Each row in groceries_data corresponds to a unique transaction.\n","    \"\"\"\n","    if groceries_data.empty:\n","        return groceries_data\n","    grouped_groceries_data = (groceries_data.groupby(\"Index\").count() >= 2).rename(columns={value_col: f\"{value_col}_2\"})\n","    groceries_data = grouped_groceries_data.merge(right=groceries_data, on=\"Index\", how=\"right\")\n","    groceries_data = groceries_data[groceries_data[f\"{value_col}_2\"] == True].drop(columns=f\"{value_col}_2\")\n","    return groceries_data\n","\n","def get_most_common_combos(groceries_data: pd.DataFrame, min_item_frequency_threshold: int, common_combo_threshold: int, value_col: str = \"uniqueTransaction\", print_steps: bool=False) -> (pd.DataFrame, pd.Series):\n","    \"\"\"\n","    We assume that each row of groceries_data is a unique transaction of a given item or set of items.\n","    Each uniqueTransaction is a list of the same length num_items_per_transaction. So num_items_per_transaction = 2 gives us the following for groceries_data:\n","    \n","    index  |  uniqueTransactions\n","    -----------------------------\n","    idx1   |  [56, 82]\n","    idx1   |  [56, 74]\n","    idx1   |  [74, 82]\n","    idx2   |  [-4, 34]\n","    \n","    We then find all combinations of size num_items_per_transaction+1, and select the most common ones\n","    (i.e. combos that appear more than common_combo_threshold times). So in the above example, the only combination would be [56, 74, 82].\n","    \n","    We also transform groceries_data to have uniqueTransactions with length num_items_per_transaction+1. This would then give us:\n","    \n","    index  |  uniqueTransactions\n","    -----------------------------\n","    idx1   |  [56, 74, 82]\n","    \"\"\"\n","\n","    # Here, we just select items or sets of items bought more than (or equal to) item_frequency_threshold times.\n","    groceries_data = select_items_bought_with_high_frequency(groceries_data, value_col, min_item_frequency_threshold)\n","    \n","    if groceries_data.empty:\n","        return groceries_data, pd.Series([], name=\"count\", dtype='int64')\n","    \n","    # Transform groceries_data to have unique indices and a long list of all items with that index, rather than one row per unique transaction.\n","    num_items_per_transaction = len(groceries_data[value_col].iloc[0])\n","    groceries_data = get_rows_with_num_transactions(groceries_data, value_col)\n","    groceries_data = pd.DataFrame(groceries_data.groupby(\"Index\")[value_col].apply(lambda x: sorted(list(set(chain(*x)))))).rename(columns={value_col: \"allItems\"})\n","\n","    # Get all possible combinations for each index\n","    groceries_data[\"combos\"] = groceries_data[\"allItems\"].apply(lambda x: list(list(combo) for combo in (combinations(x, num_items_per_transaction+1))))\n","    if print_steps:\n","        print(f\"\\nGetting list of all items and combinations of length {num_items_per_transaction+1} for each unique index\")\n","        print(groceries_data.head())\n","    \n","    # Getting the combinations of size num_items_per_transaction + 1 that occur more than or equal to common_combo_threshold times.\n","    grocery_combos = list(chain(*groceries_data[\"combos\"].values.tolist()))\n","    combo_counts = pd.Series(grocery_combos).value_counts()\n","    combo_counts = combo_counts[combo_counts >= common_combo_threshold]\n","    if print_steps:\n","        print(f\"\\nGetting the common combinations of length {num_items_per_transaction+1}\")\n","        print(combo_counts)\n","    \n","    # Transform groceries_data to again have uniqueTransactions, but with a higher num_items_per_transaction by 1.\n","    groceries_data = groceries_data[[\"combos\"]].explode(\"combos\").rename(columns={\"combos\": value_col})\n","    \n","    # Keep only the rows where the combination is one of the common ones.\n","    groceries_data = groceries_data[groceries_data[value_col].isin(combo_counts.index)]\n","\n","    return groceries_data, combo_counts\n","\n","# We get the most common combinations of lengths 2 to 4 inclusive and set the common_combo_threshold lower for larger combination lengths.\n","# This is arbitrary, but it feels right. I don't expect common combos of 4 to happen as often as common combos of 2.\n","combinations_dict = dict()\n","combo_size_and_threshold_dict = {2: 70, 3: 50, 4: 20}\n","\n","for combination_size, common_combo_threshold in combo_size_and_threshold_dict.items():\n","    \n","    # To give an idea of what's going on under the hood, I'm printing out the steps for combination_size 2\n","    print_steps = False\n","    if combination_size == 2:\n","        print_steps = True\n","    groceries_apriori, combo_counts = get_most_common_combos(groceries_data = groceries_apriori,\n","                           min_item_frequency_threshold = 48,\n","                           common_combo_threshold = common_combo_threshold,\n","                           value_col = \"uniqueTransaction\",\n","                           print_steps = print_steps)\n","    combinations_dict[combination_size] = combo_counts"]},{"cell_type":"markdown","id":"54571e0e","metadata":{"papermill":{"duration":0.007852,"end_time":"2024-08-04T23:23:20.2044","exception":false,"start_time":"2024-08-04T23:23:20.196548","status":"completed"},"tags":[]},"source":["Let's take a look at our common combinations. We turn the item numbers back into their original item descriptions, because looking at a bunch of numbers isn't terribly useful in this case."]},{"cell_type":"code","execution_count":9,"id":"bddde4d1","metadata":{"execution":{"iopub.execute_input":"2024-08-04T23:23:20.22202Z","iopub.status.busy":"2024-08-04T23:23:20.221571Z","iopub.status.idle":"2024-08-04T23:23:20.25906Z","shell.execute_reply":"2024-08-04T23:23:20.257846Z"},"papermill":{"duration":0.050296,"end_time":"2024-08-04T23:23:20.262505","exception":false,"start_time":"2024-08-04T23:23:20.212209","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Combo size 2:\n","               Item1             Item2  Count\n","0   other vegetables        whole milk    222\n","1         rolls/buns        whole milk    209\n","2               soda        whole milk    174\n","3         whole milk            yogurt    167\n","4   other vegetables        rolls/buns    158\n","5   other vegetables              soda    145\n","6            sausage        whole milk    134\n","7     tropical fruit        whole milk    123\n","8   other vegetables            yogurt    121\n","9         rolls/buns              soda    121\n","10        rolls/buns            yogurt    117\n","11   root vegetables        whole milk    113\n","12      bottled beer        whole milk    107\n","13     bottled water        whole milk    107\n","14      citrus fruit        whole milk    107\n","15         pip fruit        whole milk     99\n","16            pastry        whole milk     97\n","17     shopping bags        whole milk     95\n","18  other vegetables    tropical fruit     94\n","19        rolls/buns    tropical fruit     91\n","20  other vegetables           sausage     90\n","21       canned beer        whole milk     90\n","22           sausage              soda     89\n","23              soda            yogurt     87\n","24        rolls/buns   root vegetables     86\n","25           sausage            yogurt     86\n","26        newspapers        whole milk     84\n","27     bottled water  other vegetables     82\n","28              soda    tropical fruit     81\n","29        rolls/buns           sausage     80\n","30     domestic eggs        whole milk     79\n","31       frankfurter        whole milk     79\n","32   root vegetables              soda     79\n","33  other vegetables   root vegetables     79\n","34    tropical fruit            yogurt     78\n","35       frankfurter  other vegetables     77\n","36              pork        whole milk     75\n","37  other vegetables     shopping bags     74\n","38  other vegetables         pip fruit     74\n","39         pip fruit        rolls/buns     74\n","40      citrus fruit  other vegetables     72\n","41     bottled water              soda     72\n","42        rolls/buns     shopping bags     71\n","43      bottled beer  other vegetables     70\n","44     bottled water        rolls/buns     70\n","45              beef        whole milk     70\n","46            butter        whole milk     70\n","47      citrus fruit        rolls/buns     70\n","\n","Combo size 3:\n","Empty DataFrame\n","Columns: [Item1, Item2, Count]\n","Index: []\n","\n","Combo size 4:\n","Empty DataFrame\n","Columns: [Item1, Item2, Count]\n","Index: []\n"]}],"source":["for combination_size, combos in combinations_dict.items():\n","    combos_values = combos.values\n","    combos = pd.DataFrame(combos.index.values.tolist(), columns=[\"Item1\", \"Item2\"]).replace(itemEncoderDict)\n","    combos[\"Count\"] = combos_values\n","    \n","    print(f\"\\nCombo size {combination_size}:\")\n","    print(combos)\n","    \n","    combinations_dict[combination_size] = combos"]},{"cell_type":"markdown","id":"9f058051","metadata":{"papermill":{"duration":0.008024,"end_time":"2024-08-04T23:23:20.278617","exception":false,"start_time":"2024-08-04T23:23:20.270593","status":"completed"},"tags":[]},"source":["Oh, wow. There are no common transactions with more than 2 items. I had a look at the combo_counts at combination_size 3 before the filtering step, and the highest value_count is 18. 18 occurrences of the same combination in 2 years (mind that we started with 14963 unique combinations of date and member in the data) is really nothing.\n","\n","From the looks of it, whole milk is incredibly popular and tends to be bought with a bunch of other things, and vegetables or rolls/buns are also fairly common to buy with other things, although buying 3 such common items at once is obviously a rarity."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":877335,"sourceId":1494131,"sourceType":"datasetVersion"},{"datasetId":5495722,"sourceId":9105794,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":11.855294,"end_time":"2024-08-04T23:23:20.909448","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-08-04T23:23:09.054154","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}